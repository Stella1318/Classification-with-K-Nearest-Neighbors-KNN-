{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_ChUFBpzd0a"
   },
   "source": [
    "This is a notebook for HW1. Be careful that variable values persist, so you may end up getting strange errors that are only solved when you restart the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0eCdzLUUzHVC"
   },
   "outputs": [],
   "source": [
    "# These are imports and you do not need to modify these.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import math\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(3142021)\n",
    "random.seed(3142021)\n",
    "\n",
    "def load_data():\n",
    "    # Load the data\n",
    "    with urllib.request.urlopen(\"https://www.cs.toronto.edu/~cmaddis/courses/sta314_f21/data/clean_fake.txt\") as f:\n",
    "        fake = [l.decode(\"utf-8\").strip() for l in f]\n",
    "    with urllib.request.urlopen(\"https://www.cs.toronto.edu/~cmaddis/courses/sta314_f21/data/clean_real.txt\") as f:\n",
    "        real = [l.decode(\"utf-8\").strip() for l in f]\n",
    "        \n",
    "    # Print some sample observations\n",
    "    print(\"Sample Real Headlines:\")\n",
    "    print(\"\\n\".join(real[:5]))  # Print first 5 real headlines\n",
    "    print(\"\\nSample Fake Headlines:\")\n",
    "    print(\"\\n\".join(fake[:5]))  # Print first 5 fake headlines\n",
    "\n",
    "\n",
    "    # Each element is a string, corresponding to a headline\n",
    "    data = np.array(real + fake)\n",
    "    labels = np.array([0]*len(real) + [1]*len(fake))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Real Headlines:\n",
      "donald trump do you remember the year since he was elected\n",
      "trump defends son over emails as moscow hits back\n",
      "donald trump strategist says media wont easily give back america\n",
      "anthony scaramucci who is donald trumps new comms director\n",
      "donald trumps mobile phone use worries security experts\n",
      "\n",
      "Sample Fake Headlines:\n",
      "trump warns of vote flipping on machines\n",
      "this election is not about trump its about a giant middle finger to washington dc\n",
      "more on trump populism and how it can be controlled by government\n",
      "trump bollywood ad meant to sway indian american voters is an hilarious fail\n",
      "dems could be up on charges for inciting trump rally violence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['donald trump do you remember the year since he was elected',\n",
       "        'trump defends son over emails as moscow hits back',\n",
       "        'donald trump strategist says media wont easily give back america',\n",
       "        ...,\n",
       "        'breaking donald trump makes major clinton indictment announcement details',\n",
       "        'no hate crimes have not intensified since trump election',\n",
       "        'who to blame for president trump'], dtype='<U198'),\n",
       " array([0, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XfuC9nQPzQy1"
   },
   "outputs": [],
   "source": [
    "def process_data(data, labels):\n",
    "    \"\"\"\n",
    "    Preprocess a dataset of strings into vector representations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: numpy array\n",
    "        An array of N strings.\n",
    "    labels: numpy array\n",
    "        An array of N integer labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_X: numpy array\n",
    "        Array with shape (N, D) of N inputs.\n",
    "    train_Y:\n",
    "        Array with shape (N,) of N labels.\n",
    "    val_X:\n",
    "        Array with shape (M, D) of M inputs.\n",
    "    val_Y:\n",
    "        Array with shape (M,) of M labels.\n",
    "    test_X:\n",
    "        Array with shape (M, D) of M inputs.\n",
    "    test_Y:\n",
    "        Array with shape (M,) of M labels.\n",
    "    \"\"\"\n",
    "\n",
    "   # Step 1: Split the dataset into training, validation, and test sets (70/15/15)\n",
    "    train_X, temp_X, train_Y, temp_Y = train_test_split(\n",
    "        data, labels, test_size=0.30, stratify=labels, random_state=3142021\n",
    "    )\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(\n",
    "        temp_X, temp_Y, test_size=0.50, stratify=temp_Y, random_state=3142021\n",
    "    )\n",
    "\n",
    "    # Step 2: Preprocess the data using CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # Fit the vectorizer only on the training data, then transform all sets\n",
    "    train_X = vectorizer.fit_transform(train_X)\n",
    "    val_X = vectorizer.transform(val_X)\n",
    "    test_X = vectorizer.transform(test_X)\n",
    "\n",
    "    # Convert sparse matrices to dense arrays for easier use\n",
    "    train_X = train_X.toarray()\n",
    "    val_X = val_X.toarray()\n",
    "    test_X = test_X.toarray()\n",
    "\n",
    "    # Return the training, validation, and test sets\n",
    "    return train_X, train_Y, val_X, val_Y, test_X, test_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z2E0tFcZzbu6"
   },
   "outputs": [],
   "source": [
    "def select_knn_model(train_X, val_X, train_Y, val_Y):\n",
    "    \"\"\"\n",
    "    Test k in {1, ..., 20} and return the a k-NN model\n",
    "    fitted to the training set with the best validation loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_X: numpy array\n",
    "        Array with shape (N, D) of N inputs.\n",
    "    train_Y: numpy array\n",
    "        Array with shape (M, D) of M inputs.\n",
    "    train_Y: numpy array\n",
    "        Array with shape (N,) of N labels.\n",
    "    val_Y: numpy array\n",
    "        Array with shape (M,) of M labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_model : KNeighborsClassifier\n",
    "        The best k-NN classifier fit on the training data \n",
    "    and selected according to validation loss.\n",
    "    best_k : int\n",
    "        The best k value according to validation loss.\n",
    "    \"\"\"\n",
    "    best_k = None\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Test k values from 1 to 20\n",
    "    for k in range(1, 21):\n",
    "        # Initialize the k-NN classifier with the current k\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        # Train the model on the training data\n",
    "        model.fit(train_X, train_Y)\n",
    "        \n",
    "        # Make predictions on the validation data\n",
    "        val_pred = model.predict(val_X)\n",
    "        \n",
    "        # Calculate accuracy on the validation set\n",
    "        accuracy = accuracy_score(val_Y, val_pred)\n",
    "        \n",
    "        # Update the best model if this one performs better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_k = k\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY13RYNLztWg"
   },
   "source": [
    "Run the next cell to get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data, labels = load_data()\n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = process_data(data, labels)\n",
    "\n",
    "    best_model, best_k = select_knn_model(train_X, val_X, train_Y, val_Y)\n",
    "    test_accuracy = best_model.score(test_X, test_Y)\n",
    "    print(\"Selected K: {}\".format(best_k))\n",
    "    print(\"Test Acc: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xg8Fb725zv_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Real Headlines:\n",
      "donald trump do you remember the year since he was elected\n",
      "trump defends son over emails as moscow hits back\n",
      "donald trump strategist says media wont easily give back america\n",
      "anthony scaramucci who is donald trumps new comms director\n",
      "donald trumps mobile phone use worries security experts\n",
      "\n",
      "Sample Fake Headlines:\n",
      "trump warns of vote flipping on machines\n",
      "this election is not about trump its about a giant middle finger to washington dc\n",
      "more on trump populism and how it can be controlled by government\n",
      "trump bollywood ad meant to sway indian american voters is an hilarious fail\n",
      "dems could be up on charges for inciting trump rally violence\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f4a2df52e9ba>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_knn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected K: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5eeb72d77511>\u001b[0m in \u001b[0;36mselect_knn_model\u001b[0;34m(train_X, val_X, train_Y, val_Y)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Calculate accuracy on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Update the best model if this one performs better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
